import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import time
import glob
import math
import pickle

train_set = pd.read_csv("UJIIndoorLoc_trainingData.csv")

test_set = pd.read_csv("UJIIndoorLoc_validationData.csv")

train_set.loc[train_set["BUILDINGID"] == 0]["FLOOR"].unique()
train_set.loc[train_set["BUILDINGID"] == 1]["FLOOR"].unique()
train_set.loc[train_set["BUILDINGID"] == 2]["FLOOR"].unique()

train_set.columns.values
plt.hist(train_set.loc[train_set["BUILDINGID"] == 0]["LONGITUDE"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 0]["LATITUDE"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 0]["FLOOR"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 0]["BUILDINGID"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 0]["SPACEID"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 0]["RELATIVEPOSITION"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 0]["USERID"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 0]["PHONEID"])

plt.hist(train_set.loc[train_set["BUILDINGID"] == 1]["LONGITUDE"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 1]["LATITUDE"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 1]["FLOOR"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 1]["BUILDINGID"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 1]["SPACEID"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 1]["RELATIVEPOSITION"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 1]["USERID"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 1]["PHONEID"])

plt.hist(train_set.loc[train_set["BUILDINGID"] == 2]["LONGITUDE"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 2]["LATITUDE"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 2]["FLOOR"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 2]["BUILDINGID"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 2]["SPACEID"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 2]["RELATIVEPOSITION"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 2]["USERID"])
plt.hist(train_set.loc[train_set["BUILDINGID"] == 2]["PHONEID"])

plt.hist(train_set["LONGITUDE"])
plt.hist(train_set["LATITUDE"])
plt.hist(train_set["FLOOR"])
plt.hist(train_set["BUILDINGID"])
plt.hist(train_set["SPACEID"])
plt.hist(train_set["RELATIVEPOSITION"])
plt.hist(train_set["USERID"])
plt.hist(train_set["PHONEID"])

pd.isnull(train_set)
pd.isnull(train_set).values.any()

test_set.loc[test_set["BUILDINGID"] == 0]["FLOOR"].unique()  # building 0 has 4 floors
test_set.loc[test_set["BUILDINGID"] == 1]["FLOOR"].unique()  # building 1 has 4 floors
test_set.loc[test_set["BUILDINGID"] == 2]["FLOOR"].unique()  # building 2 has 5 floors

test_set.columns.values
plt.hist(test_set.loc[test_set["BUILDINGID"] == 0]["LONGITUDE"])
plt.hist(test_set.loc[test_set["BUILDINGID"] == 0]["LATITUDE"])
plt.hist(test_set.loc[test_set["BUILDINGID"] == 0]["FLOOR"])
plt.hist(test_set.loc[test_set["BUILDINGID"] == 0]["BUILDINGID"])
plt.hist(test_set.loc[test_set["BUILDINGID"] == 0]["PHONEID"])

plt.hist(test_set.loc[test_set["BUILDINGID"] == 1]["LONGITUDE"])
plt.hist(test_set.loc[test_set["BUILDINGID"] == 1]["LATITUDE"])
plt.hist(test_set.loc[test_set["BUILDINGID"] == 1]["FLOOR"])
plt.hist(test_set.loc[test_set["BUILDINGID"] == 1]["BUILDINGID"])
plt.hist(test_set.loc[test_set["BUILDINGID"] == 1]["PHONEID"])

plt.hist(test_set.loc[test_set["BUILDINGID"] == 2]["LONGITUDE"])
plt.hist(test_set.loc[test_set["BUILDINGID"] == 2]["LATITUDE"])
plt.hist(test_set.loc[test_set["BUILDINGID"] == 2]["FLOOR"])
plt.hist(test_set.loc[test_set["BUILDINGID"] == 2]["BUILDINGID"])
plt.hist(test_set.loc[test_set["BUILDINGID"] == 2]["PHONEID"])

plt.hist(test_set["LONGITUDE"])
plt.hist(test_set["LATITUDE"])
plt.hist(test_set["FLOOR"])
plt.hist(test_set["BUILDINGID"])
plt.hist(test_set["PHONEID"])

pd.isnull(test_set)
pd.isnull(test_set).values.any()

train_set.iloc[:, 0:520].min().min()
train_set_P = train_set.copy()
train_set_P.iloc[:, 0:520] = np.where(train_set_P.iloc[:, 0:520] <= 0,
                                      train_set_P.iloc[:, 0:520] + 105,
                                      train_set_P.iloc[:, 0:520] - 100)

combined = pd.concat([train_set_P, test_set])
combined = combined.assign(UNIQUELOCATION=(
            combined['LONGITUDE'].astype(str) + '_' + combined['LATITUDE'].astype(str) + '_' + combined['FLOOR'].astype(
        str) + '_' + combined['BUILDINGID'].astype(str)).astype('category').cat.codes)
len(combined["UNIQUELOCATION"].unique())

train_set_PU = combined.iloc[0:19937, :]
test_set_U = combined.iloc[19937:21048, :]

train_set_PU["UNIQUELOCATION"] = train_set_PU["UNIQUELOCATION"].astype("category")
train_set_PU.dtypes

X_train = train_set_PU.iloc[:, 0:520]
y_train = train_set_PU.iloc[:, 520:530]

test_set_PU = test_set_U.copy()
test_set_PU.iloc[:, 0:520] = np.where(test_set_PU.iloc[:, 0:520] <= 0, test_set_PU.iloc[:, 0:520] + 105,
                                      test_set_PU.iloc[:, 0:520] - 100)

test_set_PU["UNIQUELOCATION"] = test_set_PU["UNIQUELOCATION"].astype("category")
test_set_PU.dtypes

X_test = test_set_PU.iloc[:, 0:520]
y_test = test_set_PU.iloc[:, 520:530]

ref_table = pd.concat([y_train.iloc[:, [0, 1, 2, 3, 9]], y_test.iloc[:, [0, 1, 2, 3, 9]]])
ref_table = ref_table.drop_duplicates()


def save_data(dataframe, filename):
    file_present = glob.glob(filename)
    if not file_present:
        dataframe.to_csv(filename)
    else:
        print('WARNING: This file already exists.')


save_data(X_train, 'X_train_knn.csv')
save_data(y_train, 'y_train_knn.csv')
save_data(X_test, 'X_test_knn.csv')
save_data(y_test, 'y_test_knn.csv')

X_train = pd.read_csv('X_train_knn.csv', index_col=0)
y_train = pd.read_csv('y_train_knn.csv', index_col=0)
X_test = pd.read_csv('X_test_knn.csv', index_col=0)
y_test = pd.read_csv('y_test_knn.csv', index_col=0)

del train_set;
del train_set_P;
del train_set_PU;
del test_set;
del test_set_U;
del test_set_PU;
del combined

if __name__ == '__main__':
    from sklearn.neighbors import KNeighborsClassifier

    classifier = KNeighborsClassifier()

    hyperparameters = {'n_neighbors': [1],
                       'metric': ['manhattan']}

    from sklearn.model_selection import GridSearchCV
    from sklearn.metrics import cohen_kappa_score
    from sklearn.metrics import make_scorer

    scoring = {'accuracy': 'accuracy',
               'kappa': make_scorer(cohen_kappa_score)}

    grid = GridSearchCV(estimator=classifier,
                        param_grid=hyperparameters,
                        scoring=scoring,
                        cv=10,
                        refit='accuracy',
                        return_train_score=True,
                        n_jobs=-1)

    tic = time.time()
    grid_result = grid.fit(X_train, y_train.iloc[:, 9].squeeze())
    toc = time.time()
    run_time = (toc - tic) / 60
    import winsound;winsound.Beep(frequency=1500, duration=2000)

cv_results_ = pd.DataFrame.from_dict(grid_result.cv_results_)
cv_results_.insert(loc=0, column='Model',
                   value=['KNeighborsClassifier'] * cv_results_.shape[0])
cv_results_.insert(loc=58, column='mean train - cross_val accuracy',
                   value=cv_results_['mean_train_accuracy'] - cv_results_['mean_test_accuracy'])
cv_results_.insert(loc=59, column='mean train - cross_val kappa',
                   value=cv_results_['mean_train_kappa'] - cv_results_['mean_test_kappa'])
with open('tuning_knn.csv', 'a') as f:
    cv_results_.to_csv(f, header=False, index=False)

grid_result.best_estimator_
grid_result.best_score_
grid_result.best_params_


def save_model(model, model_name):
    model_name_present = glob.glob(model_name)
    if not model_name_present:
        pickle.dump(grid_result, open(model_name, 'wb'))
    else:
        print('WARNING: This file already exists.')


save_model(grid_result, 'KNeighborsClassifier_model.sav')

grid_result = pickle.load(open('KNeighborsClassifier_model.sav', 'rb'))

y_pred = grid_result.predict(X_test)
np.mean(y_pred == y_test.iloc[:, 9])

y_test_pos = y_test.iloc[:, 0:2].values
y_test_floor = y_test.iloc[:, 2].values
y_test_building = y_test.iloc[:, 3].values

dict_loc = {}
m_total = ref_table.shape[0]
for i in range(m_total):
    key = int(ref_table.iloc[i]['UNIQUELOCATION'])
    value = ref_table.iloc[i, 0:4].values
    dict_loc[key] = value

y_pred_pos = np.asarray([dict_loc[i] for i in y_pred])[:, 0:2]
y_pred_floor = np.asarray([dict_loc[i] for i in y_pred])[:, 2]
y_pred_building = np.asarray([dict_loc[i] for i in y_pred])[:, 3]


def euclidean(y_test_pos, y_pred_pos):
    m_test = y_test_pos.shape[0]
    D_error = np.sum((y_test_pos - y_pred_pos) ** 2, axis=1) ** 0.5

    return D_error


D_error = euclidean(y_test_pos, y_pred_pos)  # position errors for each test set example, in order as they appear
sorted_D_error = sorted(D_error)

m_test = y_test.shape[0]
mean_error = np.mean(D_error)  # meters
percentile_25th = sorted_D_error[math.ceil(m_test * 0.25) - 1]  # -1 since 0-indexed. meters
percentile_50th = sorted_D_error[math.ceil(m_test * 0.50) - 1]  # meters
percentile_75th = sorted_D_error[math.ceil(m_test * 0.75) - 1]  # meters
percentile_95th = sorted_D_error[math.ceil(m_test * 0.95) - 1]  # meters
percentile_100th = sorted_D_error[math.ceil(m_test * 1.00) - 1]  # meters
building_hitrate = np.mean(y_test_building == y_pred_building)
floor_hitrate = np.mean(y_test_floor == y_pred_floor)
